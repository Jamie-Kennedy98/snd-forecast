{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: dowload full excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download XLS files from a given URL\n",
    "def download_xls_files_from_page(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check that the request was successful\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    xls_links = soup.find_all('a', href=lambda x: (x.endswith('.xls') if x else False))\n",
    "\n",
    "    for link in xls_links:\n",
    "        file_url = link['href']\n",
    "        file_name = file_url.split('/')[-1]  # Extract the file name\n",
    "\n",
    "        with requests.get(file_url, stream=True) as file_response:\n",
    "            file_response.raise_for_status()\n",
    "            with open(file_name, 'wb') as f:\n",
    "                for chunk in file_response.iter_content(chunk_size=8192): \n",
    "                    f.write(chunk)\n",
    "        print(f\"Downloaded {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL and page template\n",
    "base_url = 'https://usda.library.cornell.edu/concern/publications/3t945q76s'\n",
    "page_param = '?locale=en&page='\n",
    "\n",
    "# Determine the number of pages or set a high number if unknown\n",
    "# You can manually set this, or dynamically find it if the number of pages is listed on the site\n",
    "number_of_pages = 3  # Example number, you should set this appropriately\n",
    "\n",
    "# Loop through all the pages\n",
    "for page in range(1, number_of_pages + 1):\n",
    "    page_url = f\"{base_url}{page_param}{page}#release-items\"\n",
    "    print(f\"Scraping {page_url}\")\n",
    "    download_xls_files_from_page(page_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### version 2: only download corn snd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import xlrd\n",
    "import openpyxl\n",
    "from tempfile import NamedTemporaryFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_cells(file_url, sheet_name, cell_range):\n",
    "    response = requests.get(file_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Write the file temporarily to disk\n",
    "    with NamedTemporaryFile(delete=False, suffix='.xls') as tmp:\n",
    "        temp_file_name = tmp.name\n",
    "        tmp.write(response.content)\n",
    "    \n",
    "    # Read the specific range from the .xls file\n",
    "    book = xlrd.open_workbook(temp_file_name)\n",
    "    sheet = book.sheet_by_name(sheet_name)\n",
    "\n",
    "    data = []\n",
    "    for row_idx in range(cell_range['start_row'] - 1, cell_range['end_row']):\n",
    "        row_data = []\n",
    "        for col_idx in range(cell_range['start_col'] - 1, cell_range['end_col']):\n",
    "            row_data.append(sheet.cell_value(row_idx, col_idx))\n",
    "        data.append(row_data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_to_excel(data, output_filename):\n",
    "    # Create a new Workbook\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "\n",
    "    # Write data to Workbook\n",
    "    for row_idx, row_data in enumerate(data, start=1):\n",
    "        for col_idx, value in enumerate(row_data, start=1):\n",
    "            ws.cell(row=row_idx, column=col_idx, value=value)\n",
    "    \n",
    "    # Save the workbook\n",
    "    wb.save(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the range and sheet name\n",
    "cell_range = {'start_row': 30, 'end_row': 50, 'start_col': 1, 'end_col': 5}  # A30:E50\n",
    "sheet_name = 'Page 12'\n",
    "\n",
    "# Specify the base URL and parameters\n",
    "base_url = 'https://usda.library.cornell.edu/concern/publications/3t945q76s'\n",
    "page_param = '?locale=en&page='\n",
    "\n",
    "# Specify the number of pages\n",
    "number_of_pages = 2  # Adjust as needed\n",
    "\n",
    "for page in range(1, number_of_pages + 1):\n",
    "    page_url = f\"{base_url}{page_param}{page}#release-items\"\n",
    "    soup = BeautifulSoup(requests.get(page_url).text, 'html.parser')\n",
    "    xls_links = soup.find_all('a', href=lambda x: (x and x.endswith('.xls')))\n",
    "\n",
    "    for link in xls_links:\n",
    "        file_url = link['href']\n",
    "        data = download_and_extract_cells(file_url, sheet_name, cell_range)\n",
    "\n",
    "        # Generate a filename for the new .xlsx file\n",
    "        file_name = file_url.split('/')[-1]\n",
    "        new_file_name = f\"{file_name.split('.')[0]}_reduced.xlsx\"\n",
    "        \n",
    "        # Save the data to a new .xlsx file\n",
    "        save_to_excel(data, new_file_name)\n",
    "        print(f\"Saved data to {new_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
